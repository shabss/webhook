# Webhook Design

## Motivation

This document describes the design of a webhook transport system between a sender (e.g github) and a receiver (e.g circle-ci). The system transports both initial webhook and the response of the hook as back to the sender.

Requirements:
1. Total message ordering is not required, but may be required on per application bases on the sender
2. Idempotency should be managed by the system. That is it should not send duplicate hook events to the receiver
3. System should be highly available and scalable

## Definitions
* **Sender**: The system initiating webhooks. E.g. github.com
* **Source**: An "application" within the Sender that originates message
* **Receiver**: The system that processes the webhook. E.g. circleci.com


## Architecture

### Components
We use **Kafka** as a queueing system because it offers following features:
1. High Availability
2. Message ordering (per partition)
3. Manual commit. Helps retrying failed operations

We use **Redis** as our primary database becasue it offers the following features:
1. Highly available
2. In memory fast access
3. Can be configured to be backed by disks

We use **Sentry** for monitoring and exception tracking

### Design

### Kafka Topics

1. **from_sender** : Sender pushes messages to this topic. There are 10 partitions. The partitioning key will be *source_id*. This will allow us to order messages from each source.
2. **to_sender**: This topic contains messages processed by the receiver and enqueued here for delivery to the sender. 
3. **to_receiver_<receiver_name>**: These topics contains messages that needs to be delivered to the receiver for processing the webooks. One topic each for a receiver with one partition each. Having a topic per receiver helps with managing rate limits and one partition helps with message ordering. 
4. **pending_from_receiver_<receiver_name>**: These topics store the events that are delivered to receiver but the response has not arrived yet. For each message in these topic we "ping" the receiver for a response and if one has arrived, we push it to "to_sender" topic.
5. **failed_messages**: The topic contains all the messages that have failed

### Databases
1. **messages**: Database that keeps track of webhook messages and to dedup duplicate messages. 
   1. PK: (source_id, message_id), values: (payload, status)
   1. (source_id, message_id) is generated by the sender and must be unique
   1. Payload is in json format and contains the information about the webhook, including the receiver name
   1. Status: can be one of:
      1. ARRIVED
      1. DELIVERED_TO_RECEIVER
      1. RESPONSE_RECEIVED_FROM_RECEIVER
      1. RESPONSE_DELIVERED_TO_SENDER (aka DONE)
1. **message_tracking**: Database that contains message tracking information. This helps with retries in case of failure. 
   1. PK: (source_id, message_id), values: (num_retries, last_sent_timestamp)
1. **message_ttl**: Database that assists with message tracking. When entries in this table expire, we need to retry the message again or fail.
   1. PK: (source_id, message_id). Add to database with TTL as configured in receiver config
1. **receiver_config**: Receiver configuration database. The data in the table is as follows:
   1. receiver_name (PK): Name of the receiver. 
   1. Rate related:
      1. rate_limit: Rate limit (msgs / window_size) that the receiver allows.
      1. window_size: Size of the window in seconds in which rate_limit applies. 
      1. current_rate: Number of messages in current window.
   1. Retry related:
      1. retry_after: number of seconds to retry after
   1. post_endpoint: endpoint to send message to
   1. status_endpoint: endpoint to check status from.


### Workers
Workers are as follows:
1. **FromSenderWorker**: This worker does the following operations:
   1. Read, without autocommit, message from the *from_sender* queue. 
   2. Checks the message in *messages* database. If already present then drops it, i.e. commits the message on kafka and continues to read the next message
   3. Otherwise, adds the message to *messages* database
   4. Finds the receiver_name from message and sends the message to *to_receiver_<receiver_name>* topic
   5. If any failure happens, it sends the message to *failed_messages* topic
   6. Commits the message on kafka
1. **ToSenderWorker**: 
   1. Read, without autocommit, message from the *to_sender* queue.
   2. Sends the message to the (original) Sender via http post
      1. If send is successful:
         1. Deletes message from *messages*, *message_tracking*, *message_ttl* databases
         1. Commits the message on kafka
      2. If not successful, waits and retries. if retries limit is reached then sends message to *failed_messages* topic
1. **ToReceiverWorker**: This worker listens on *to_receiver_<receiver_name>* topic. Note that this specific to each receiver and has one partition. Thus, each worker is handling messages only for this receiver. The worker does the following operations:
   1. Read, without autocommit, message from the *to_receiver_<receiver_name>* queue.
   2. Checks the *receiver_config* and *message_tracking* databases to understand if rate limits have been reached for this receiver or num_retries have expired.
      1. If rate limit has been reached, then waits for a while and tries again
      2. If max retries have been reached then sends the message to *failed_messages* topic
   1. Sends the message to receiver via HTTP POST
   1. Updates the message status in *messages* database as DELIVERED_TO_RECEIVER
   1. If response contains message results then:
      1. Updates the message status in *messages* database as RESPONSE_RECEIVED_FROM_RECEIVER
      2. sends the response to *to_sender* topic
   1. If response does not contain results (that is message is accepted with results pending), then:
      1. Sends a message to *pending_from_receiver_<receiver_name>*
   1. If any failure happens, it sends the message to *failed_messages* topic
   1. Commits the message on kafka
1. **FromRecieverAsyncWorker**: This worker checks for response from a receiver for a particular message. 
   1. Read, without autocommit, message from the *pending_from_receiver_<receiver_name>* queue.
   1. Continuously pings the receiver to get message status and results. 
      1. If results are available:
         1. Updates the message status in *messages* database as RESPONSE_RECEIVED_FROM_RECEIVER
         1. sends the response to *to_sender* topic
      1. Otherwise waits for a certain amount of time and retries
   1. Commits the message to kafka
1. **Failed Messages Worker**:
   2. ToDo

## Data Flow

### Forward Flow

    Sender -> [from_sender topic] -> FromSenderWorker -> [to_receiver_<receiver_name> topic] -> ToReceiverWorker -> [HTTP POST] -> Receiver 
                                          |                                                            |
                              (dedup, message tracking)                                       (rate limit, retry)


### Backward Flow (synchronous)

    Sender <- ToSenderWorker -> [to_sender topic] <- ToReceiverWorker <- [HTTP POST response (sync)] <- Receiver 

### Backward Flow (asynchronous)

    [pending_from_receiver_<receiver_name> topic] -> ReceiverStatusAsyncWorker -> [HTTP GET] -> Receiver
                                                             .
                                                             .
                                                             .
    Sender <- ToSenderWorker -> [to_sender topic] <- ReceiverStatusAsyncWorker <- [HTTP GET] <- Receiver 


## Possible Issues:
1. ToReceiverWorker fails. Since receiver is not under our control, it is hard to detect in the forward path whether if HTTP POST has been sent before failure occurred. E.g it is possible that HTTP POST was receiver by the but failure happened when it tried to send us an ack. We also do not know if receiver is idempotent or not, perhaps it is maintaining a counter e.g. In this case the system will resend the message again, which will violate exactly once delivery guarantees.
   1. A solution would be that receiver allows us to find the status of our message and responds with 404 if it has not seen it before.  